{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "351b11b7-0dfd-4057-a07a-5b855a448b48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (2750, 4)\n",
      "\n",
      "Column types:\n",
      " text           object\n",
      "generated       int64\n",
      "text_length     int64\n",
      "word_count      int64\n",
      "dtype: object\n",
      "\n",
      "Missing values:\n",
      " text           0\n",
      "generated      0\n",
      "text_length    0\n",
      "word_count     0\n",
      "dtype: int64\n",
      "\n",
      "Counts of AI vs Human:\n",
      " generated\n",
      "1    1375\n",
      "0    1375\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Summary stats\n",
      "        text_length   word_count\n",
      "count  2750.000000  2750.000000\n",
      "mean   1670.922909   290.771273\n",
      "std    1654.118253   291.090474\n",
      "min      78.000000    13.000000\n",
      "25%      95.000000    14.000000\n",
      "50%    1896.500000   304.500000\n",
      "75%    2987.000000   525.000000\n",
      "max    8436.000000  1360.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "file = r\"C:\\Users\\ambsc\\Downloads\\balanced_ai_human_prompts.csv\"\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "df['text_length'] = df['text'].astype(str).apply(len)        \n",
    "df['word_count'] = df['text'].astype(str).str.split().str.len()\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumn types:\\n\", df.dtypes)\n",
    "print(\"\\nMissing values:\\n\", df.isna().sum())\n",
    "print(\"\\nCounts of AI vs Human:\\n\", df['generated'].value_counts())\n",
    "print(\"\\nSummary stats\\n\", df[['text_length','word_count']].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04993ef1-b49b-42d0-a37c-bbf50b1ee8ee",
   "metadata": {},
   "source": [
    "Data Information:\n",
    "\n",
    "Source - Kaggle.com\n",
    "\n",
    "Name - Human Vs AI Generated Essays\n",
    "\n",
    "Uploader - Navjot Kaushal · Updated a month ago\n",
    "\n",
    "Navjot Kaushal · Updated a month ago \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975d7bde-a91e-492a-b3e2-3b0d236f833b",
   "metadata": {},
   "source": [
    "The dataset contains 4 variables being text, generated, text length, and word count. It has 2,750 observations\n",
    "\n",
    "The text column is stored as strings while generated, text length, and word count are integers\n",
    "\n",
    "There are no missing values\n",
    "\n",
    "The dataset is  balanced with 1,375 AI-generated prompts and 1,375 human-written prompts\n",
    "\n",
    "The text length ranges from 78 to 8,436 characters, with a mean of 1,670.9 characters\n",
    "\n",
    "The word count ranges from 13 to 1,360 words, with a mean of 290.8 words\n",
    "\n",
    "The median text length is 1,896.5 characters, but it includes some prompts that are extremely long which could skew the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3fda8b0-d5c4-49c3-b71d-96031ebabd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average text length (AI): 169.3 characters\n",
      "Average text length (Human): 3172.6 characters\n",
      "Difference (AI - Human): -3003.3 characters\n"
     ]
    }
   ],
   "source": [
    "mean_ai = df[df['generated']==1]['text_length'].mean()\n",
    "mean_human = df[df['generated']==0]['text_length'].mean()\n",
    "diff = mean_ai - mean_human\n",
    "\n",
    "print(f\"Average text length (AI): {mean_ai:.1f} characters\")\n",
    "print(f\"Average text length (Human): {mean_human:.1f} characters\")\n",
    "print(f\"Difference (AI - Human): {diff:.1f} characters\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b40a5c-ef53-4d65-8a6e-8583ab48eb0b",
   "metadata": {},
   "source": [
    "Average text length for AI generated prompts: 169.3 characters\n",
    "\n",
    "Average text length for human prompts: 3,172.6 characters\n",
    "\n",
    "Difference (AI - Human): -3,003.3 characters\n",
    "\n",
    "From this we can conclude that human-written prompts are much longer on average than AI generated prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f0fc8b7-a352-4565-b5c2-189c09a24c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset saved as 'balanced_ai_human_prompts_subset.csv'\n"
     ]
    }
   ],
   "source": [
    "subset = df[['text','generated','text_length','word_count']]\n",
    "subset.to_csv(\"balanced_ai_human_prompts_subset.csv\", index=False)\n",
    "print(\"Subset saved as 'balanced_ai_human_prompts_subset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbfcbf4-ae61-40ca-a62c-21790bc9322b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
